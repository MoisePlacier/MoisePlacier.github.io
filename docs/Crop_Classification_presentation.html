<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Moïse Placier">

<title>Project Crop classification</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-B9BQN0XN58"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-B9BQN0XN58', { 'anonymize_ip': true});
</script>


<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./Crop_Classification_presentation.html">Project Crop Type Classification</a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Moïse Placier Porfolio</a> 
        <div class="sidebar-tools-main">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">curriculum vitae</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Exp_pro_en.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Professional experiences</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Educ_en.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Education</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Crop_Classification_presentation.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Project Crop Type Classification</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#context" id="toc-context" class="nav-link active" data-scroll-target="#context">Context</a></li>
  <li><a href="#crop-type-classification-from-multispectral-time-series-using-deep-learning" id="toc-crop-type-classification-from-multispectral-time-series-using-deep-learning" class="nav-link" data-scroll-target="#crop-type-classification-from-multispectral-time-series-using-deep-learning">Crop Type Classification from Multispectral Time Series Using Deep Learning</a>
  <ul class="collapse">
  <li><a href="#dataset-description" id="toc-dataset-description" class="nav-link" data-scroll-target="#dataset-description">Dataset Description</a>
  <ul class="collapse">
  <li><a href="#ground-truth-crop-labels" id="toc-ground-truth-crop-labels" class="nav-link" data-scroll-target="#ground-truth-crop-labels">Ground Truth (Crop Labels)</a></li>
  <li><a href="#satellite-data" id="toc-satellite-data" class="nav-link" data-scroll-target="#satellite-data">Satellite Data</a></li>
  <li><a href="#data-sampling" id="toc-data-sampling" class="nav-link" data-scroll-target="#data-sampling">Data sampling</a></li>
  <li><a href="#train-validation-test-splitting-strategy" id="toc-train-validation-test-splitting-strategy" class="nav-link" data-scroll-target="#train-validation-test-splitting-strategy">Train / Validation / Test Splitting Strategy</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#models" id="toc-models" class="nav-link" data-scroll-target="#models">Models</a>
  <ul class="collapse">
  <li><a href="#deep-learning-approach" id="toc-deep-learning-approach" class="nav-link" data-scroll-target="#deep-learning-approach">Deep Learning approach :</a></li>
  <li><a href="#xgboost-approach-pixel-wise-classification" id="toc-xgboost-approach-pixel-wise-classification" class="nav-link" data-scroll-target="#xgboost-approach-pixel-wise-classification">XGBoost approach (Pixel-wise Classification)</a></li>
  <li><a href="#biblio" id="toc-biblio" class="nav-link" data-scroll-target="#biblio">biblio</a></li>
  <li><a href="#authors" id="toc-authors" class="nav-link" data-scroll-target="#authors">Authors</a></li>
  </ul></li>
  <li><a href="#final-evaluation" id="toc-final-evaluation" class="nav-link" data-scroll-target="#final-evaluation">Final Evaluation</a>
  <ul class="collapse">
  <li><a href="#grade-1.0-97" id="toc-grade-1.0-97" class="nav-link" data-scroll-target="#grade-1.0-97">Grade: 1.0 (97%)</a></li>
  <li><a href="#evaluated-on-monday-july-21-2025-1857" id="toc-evaluated-on-monday-july-21-2025-1857" class="nav-link" data-scroll-target="#evaluated-on-monday-july-21-2025-1857">Evaluated on: Monday, July 21, 2025, 18:57</a></li>
  <li><a href="#evaluator-teodor-chiaburu" id="toc-evaluator-teodor-chiaburu" class="nav-link" data-scroll-target="#evaluator-teodor-chiaburu">Evaluator: Teodor Chiaburu</a></li>
  <li><a href="#feedback" id="toc-feedback" class="nav-link" data-scroll-target="#feedback">Feedback</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Project Crop classification</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Moïse Placier </p>
          </div>
  </div>
    
  
    
  </div>
  

</header>

<section id="context" class="level2">
<h2 class="anchored" data-anchor-id="context">Context</h2>
<p>This project was undertaken as part of the MSc Data Science program at Berliner Hochschule für Technik (BHT), within the scope of the Machine Learning course. The objective was to develop a complete end-to-end solution for a real-world machine learning problem. We had just over three weeks to complete the project, with a final submission deadline of July 16, 2025.</p>
<p><a href="https://github.com/MoisePlacier/Crop_type_classification">GitHub Repository - Crop Type Classification</a></p>
</section>
<section id="crop-type-classification-from-multispectral-time-series-using-deep-learning" class="level1">
<h1>Crop Type Classification from Multispectral Time Series Using Deep Learning</h1>
<p>This project focuses on mapping crop types at the pixel level using multispectral satellite image time series. By leveraging both temporal and spatial information through a hybrid CNN architecture, we aim to accurately classify agricultural parcels across diverse French landscapes. The approach combines 1D convolutions for temporal encoding and a simplified U-Net for spatial segmentation.</p>
<section id="dataset-description" class="level2">
<h2 class="anchored" data-anchor-id="dataset-description">Dataset Description</h2>
<section id="ground-truth-crop-labels" class="level3">
<h3 class="anchored" data-anchor-id="ground-truth-crop-labels">Ground Truth (Crop Labels)</h3>
<section id="data-description" class="level4">
<h4 class="anchored" data-anchor-id="data-description">Data description</h4>
<p>For ground truth values, we utilize the 2023 Graphical Parcel Register (RPG) as the reference source. This dataset, provided as a shapefile, consists of polygons that precisely delineate agricultural parcels. Each polygon corresponds to an individual field and contains essential information: a unique identifier, its surface area measured in hectares (HA), and the identifier of the predominant crop grown on it during the 2023 cultivation season. The area covered is the entire contry with a total number of 9 797 405 parcels.</p>
<ul>
<li><a href="https://www.geoportail.gouv.fr/donnees/registre-parcellaire-graphique-rpg-2023">online visualisation</a></li>
<li><a href="https://data.geopf.fr/telechargement/download/RPG/RPG_2-2__GPKG_LAMB93_FXX_2023-01-01/RPG_2-2__GPKG_LAMB93_FXX_2023-01-01.7z">downloading link</a></li>
</ul>
</section>
<section id="data-cleaning" class="level4">
<h4 class="anchored" data-anchor-id="data-cleaning">Data cleaning</h4>
<p>We needed to clean the predominant crop identifier from the Registre Parcellaire Graphique (RPG) data. While the RPG encoding is useful for the Common Agricultural Policy (PAC), it isn’t ideal for our classification task.</p>
<p>For instance, the RPG distinguishes between “sweet maize” and “maize” with separate crop IDs. However, these two share a nearly identical spectral signature, making their separation irrelevant for our classification purposes. This initial RPG classification also results in an excessively large number of classes.</p>
<p>By using the classes defined by <a href="https://arxiv.org/pdf/2102.08820">Turkoglu et al.</a>, we leverage an expert-crafted set of more meaningful and spectrally distinct crop categories. This approach effectively addresses the over-granularity of the RPG, merging spectrally similar crops (like sweet maize and maize) into single, relevant categories, and significantly reducing the total number of classes to a practical size for our classification.</p>
<p>We also reprojected the CRS of parcel geometries (Lambert 93 : EPSG:2154) to match Sentinel-2’s projection system (WGS84: reproject each tile to its native UTM zone ), guaranting accurate overlay.</p>
</section>
</section>
<section id="satellite-data" class="level3">
<h3 class="anchored" data-anchor-id="satellite-data">Satellite Data</h3>
<p>We rely on Sentinel-2 Level-2A (Surface Reflectance) images: <a href="https://developers.google.com/earth-engine/datasets/catalog/COPERNICUS_S2_SR_HARMONIZED?hl=fr">Harmonized Sentinel-2 MSI: MultiSpectral Instrument, Level-2A (SR)</a></p>
<p>We leverages 4 spectral bands from Sentinel-2 satellites to perform crop detection. These bands allow us to extract detailed information about vegetation based on light reflectance at specific wavelengths.</p>
<section id="the-following-bands-are-used" class="level4">
<h4 class="anchored" data-anchor-id="the-following-bands-are-used">The following bands are used:</h4>
<table class="table">
<colgroup>
<col style="width: 5%">
<col style="width: 6%">
<col style="width: 11%">
<col style="width: 23%">
<col style="width: 51%">
</colgroup>
<thead>
<tr class="header">
<th>Band</th>
<th>Name</th>
<th>Resolution</th>
<th>Wavelength (S2A / S2B)</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>B2</td>
<td>Blue</td>
<td>10 m</td>
<td>496.6 / 492.1 nm</td>
<td>Chlorophyll detection, cloud cover analysis</td>
</tr>
<tr class="even">
<td>B3</td>
<td>Green</td>
<td>10 m</td>
<td>560 / 559 nm</td>
<td>Vegetation contrast, plant health analysis</td>
</tr>
<tr class="odd">
<td>B4</td>
<td>Red</td>
<td>10 m</td>
<td>664.5 / 665 nm</td>
<td>NDVI calculation, vegetation growth tracking</td>
</tr>
<tr class="even">
<td>B8</td>
<td>NIR</td>
<td>10 m</td>
<td>835.1 / 833 nm</td>
<td>Biomass detection, distinguishes soil vs vegetation</td>
</tr>
</tbody>
</table>
</section>
<section id="temporal-dynamics-vs-ground-truth" class="level4">
<h4 class="anchored" data-anchor-id="temporal-dynamics-vs-ground-truth">Temporal Dynamics vs Ground Truth</h4>
<p>The following animations show the temporal evolution of reflectance in four Sentinel-2 spectral bands. Below, the ground truth map is displayed for visual comparison.</p>
<div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(250px, 1fr)); gap: 20px; justify-items: center;">
<p><img src="images/gif/Alsace_B1.gif" alt="Band 1 (Coastal)" width="250px"> <img src="images/gif/Alsace_B2.gif" alt="Band 2 (Blue)" width="250px"> <img src="images/gif/Alsace_B3.gif" alt="Band 3 (Green)" width="250px"> <img src="images/gif/Alsace_B4.gif" alt="Band 4 (NIR)" width="250px"></p>
</div>
<div style="text-align: center; margin-top: 20px;">
<p><img src="images/Labels_Alsace_zoomed_improved.png" alt="Ground Truth Map" width="500px"></p>
</div>
</section>
<section id="data-cleaning-1" class="level4">
<h4 class="anchored" data-anchor-id="data-cleaning-1">Data cleaning</h4>
<p>To effectively manage clouds in our satellite imagery, we leverage the Scene Classification Layer (SCL) provided by Sentinel-2. The SCL is a band within the Sentinel-2 Level-2A product that classifies each pixel based on its content (e.g., cloud, shadow, vegetation, water, snow). We use this layer to mask out all pixels not classified as vegetation, bare soil, or water (SCL classes 4 to 7), ensuring that clouds, cloud shadows, and other atmospheric artifacts are excluded from our analysis.</p>
<p>Following the SCL masking, we compute a pixel-wise median for each month. Since each month provides between 6 and 15 images per band for a given area, the median composite is highly robust. We choose the median over the mean because it is significantly less impacted by outliers that might persist even after SCL masking (e.g., residual cloud edges or noise). This process also reduces the probability of having “absent pixels” due to clouds in our monthly composites.</p>
<p>While median compositing greatly minimizes cloud-induced gaps, some might still occur. To address these, we implemented a pixel-wise temporal interpolation strategy:</p>
<ul>
<li>For a missing pixel value in a given month: The new value is calculated as the mean of the corresponding pixel’s value from the previous month and the next month.</li>
<li>For missing values in the first month of the time series: We use the next available monthly value for that pixel.</li>
<li>For missing values in the last month of the time series: We use the last available previous monthly value for that pixel.</li>
</ul>
<p>Although this interpolation involves a nasty function with many for loops, it proves to be quite powerful in generating a complete and continuous time series of satellite imagery.</p>
</section>
</section>
<section id="data-sampling" class="level3">
<h3 class="anchored" data-anchor-id="data-sampling">Data sampling</h3>
<p>Due to the extensive size of the covered area in France, we had to reduce the dataset used for modeling. To achieve this, we selected specific zones representing distinct agricultural landscapes, characterized by predominant crops and farming practices influenced by varying pedoclimatic conditions.</p>
<p>The following table lists these key agricultural zones across France, alongside nearby towns for geographic reference:</p>
<table class="table">
<colgroup>
<col style="width: 22%">
<col style="width: 16%">
<col style="width: 19%">
<col style="width: 42%">
</colgroup>
<thead>
<tr class="header">
<th>Zone</th>
<th>Region</th>
<th>Nearby Town (Map Reference)</th>
<th>Notes</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Nord-Picardie</strong></td>
<td>Hauts-de-France</td>
<td><strong>Saint-Quentin</strong> (Aisne)</td>
<td>Surrounded by large-scale crops (wheat, sugar beet, potatoes)</td>
</tr>
<tr class="even">
<td><strong>Paris Basin</strong></td>
<td>Île-de-France / Centre</td>
<td><strong>Chartres</strong> (Eure-et-Loir)</td>
<td>Heart of the Beauce, vast cereal plains</td>
</tr>
<tr class="odd">
<td><strong>Brittany / Pays de la Loire</strong></td>
<td>Brittany / Vendée</td>
<td><strong>Vitré</strong> (Ille-et-Vilaine)</td>
<td>Mixed zone: livestock, silage maize, hedgerows</td>
</tr>
<tr class="even">
<td><strong>Southwest</strong></td>
<td>Nouvelle-Aquitaine</td>
<td><strong>Auch</strong> (Gers)</td>
<td>Cereal polyculture, maize, sunflower</td>
</tr>
<tr class="odd">
<td><strong>Southeast</strong></td>
<td>Provence, Rhône-Alpes</td>
<td><strong>Carpentras</strong> (Vaucluse)</td>
<td>Vineyards, orchards, greenhouse vegetable farming</td>
</tr>
<tr class="even">
<td><strong>Massif Central</strong></td>
<td>Auvergne</td>
<td><strong>Riom</strong> (Puy-de-Dôme)</td>
<td>Limagne plain: polyculture on volcanic plains</td>
</tr>
<tr class="odd">
<td><strong>Alsace / Lorraine</strong></td>
<td>Grand Est</td>
<td><strong>Colmar</strong> (Haut-Rhin)</td>
<td>Hillside vineyards + lowland crop farming</td>
</tr>
<tr class="even">
<td><strong>Mediterranean</strong></td>
<td>Occitanie, PACA</td>
<td><strong>Béziers</strong> (Hérault)</td>
<td>Vineyards, olive trees, vegetable crops, dry climate</td>
</tr>
</tbody>
</table>
<p>We used ESA WorldCover (10 m resolution, global) to identify highly cultivated areas for sampling. From these representative landscapes, we selected five 10&nbsp;km×10&nbsp;km zones around each. This resulted in a total dataset covering 40 zones (8 regions × 5 zones each), each spanning 100&nbsp;km^2.</p>
<p>We then extracted all parcels from the 2023 RPG that intersect with these zones, totaling 130,000 parcels with an average size of 1.5 HA. And retrieve computed median satellites images of teh studied zones for each month via the google earth engine API.</p>
<p>Despite this effort to ensure geographical diversity, we still face a highly imbalanced class distribution across crop types — some crops are vastly overrepresented while others have very few examples.</p>
<p>The figure below illustrates this imbalance (note the logarithmic scale on the y-axis).</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/Class_Distribution.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Class distribution</figcaption>
</figure>
</div>
<p>This skew can significantly affect evaluation metrics: in particular, accuracy may be misleading, as the model can achieve high accuracy by favoring dominant classes. Therefore, we also report macro-averaged metrics (precision, recall, F1-score) that treat all classes equally, regardless of frequency.</p>
</section>
<section id="train-validation-test-splitting-strategy" class="level3">
<h3 class="anchored" data-anchor-id="train-validation-test-splitting-strategy">Train / Validation / Test Splitting Strategy</h3>
<p>For each of the eight agricultural regions described above, we selected one 10×10 km zone out of the five available to serve as the test dataset. So 20% of the dataset is held out for testing, and that each region is represented in the test set.</p>
<p>This allows us to evaluate the model’s ability to generalize to completely unseen geographic areas across diverse agro-climatic contexts.</p>
<p>The remaining 32 zones were used for training and validation. To optimize model performance while managing computational cost, we adopted a 3-fold cross-validation (CV) approach on the training set. A higher number of folds (e.g., K &gt; 3) was avoided due to the long training times associated with deep learning models on large spatial-temporal datasets.</p>
<p>This spatially-aware split avoide any data leakage between training and test areas.</p>
</section>
</section>
</section>
<section id="models" class="level1">
<h1>Models</h1>
<section id="deep-learning-approach" class="level2">
<h2 class="anchored" data-anchor-id="deep-learning-approach">Deep Learning approach :</h2>
<p>Our model classifies each pixel of a multispectral time-series image into crop types by combining temporal and spatial feature extraction in a hybrid CNN architecture.</p>
<p>Input: X ∈ ℝ — a batch of multispectral sequences with 4 channels (e.g., Red, Green, Blue, NIR), T time steps, and spatial dimensions H×W.</p>
<section id="step-1-temporal-encoding-pixel-wise" class="level4">
<h4 class="anchored" data-anchor-id="step-1-temporal-encoding-pixel-wise">Step 1: Temporal Encoding (Pixel-wise)</h4>
<p>Reshape input to [B × H × W, C, T]. Apply a 1D CNN independently on each pixel’s temporal sequence. This captures temporal patterns per pixel across spectral bands and outputs D-dimensional embeddings.</p>
</section>
<section id="step-2-reshape-to-spatial-grid" class="level4">
<h4 class="anchored" data-anchor-id="step-2-reshape-to-spatial-grid">Step 2: Reshape to Spatial Grid</h4>
<p>Reshape back to [B, D, H, W], forming a pseudo-image from the temporal embeddings.</p>
</section>
<section id="step-3-spatial-encoding-image-wise" class="level4">
<h4 class="anchored" data-anchor-id="step-3-spatial-encoding-image-wise">Step 3: Spatial Encoding (Image-wise)</h4>
<p>Pass through a 2D CNN backbone (a simplified U-Net). This captures spatial context and relationships between neighboring pixels.</p>
</section>
<section id="step-4-classification" class="level4">
<h4 class="anchored" data-anchor-id="step-4-classification">Step 4: Classification</h4>
<p>The final output is per-pixel class logits with shape [B, num_classes, H, W].</p>
</section>
<section id="results" class="level4">
<h4 class="anchored" data-anchor-id="results">Results :</h4>
<p>Global Accuracy = The ratio of correctly classified pixels over the total number of pixels</p>
<p>Precision, Recall, and F1-score (Macro) = averages across all classes (i.e., unweighted mean over classes):</p>
<table class="table">
<thead>
<tr class="header">
<th><strong>Metric</strong></th>
<th><strong>Score</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Average Loss</td>
<td>0.5222</td>
</tr>
<tr class="even">
<td>Global Accuracy</td>
<td>0.8721</td>
</tr>
<tr class="odd">
<td>Macro Precision</td>
<td>0.4099</td>
</tr>
<tr class="even">
<td>Macro Recall</td>
<td>0.3544</td>
</tr>
<tr class="odd">
<td>Macro F1-score</td>
<td>0.3516</td>
</tr>
</tbody>
</table>
<p><img src="images/CNN_preds_zone1.png" class="img-fluid" alt="Predictions"> <img src="images/GT_zone1_zoomed.png" class="img-fluid" alt="Ground truth"></p>
</section>
</section>
<section id="xgboost-approach-pixel-wise-classification" class="level2">
<h2 class="anchored" data-anchor-id="xgboost-approach-pixel-wise-classification">XGBoost approach (Pixel-wise Classification)</h2>
<p>In addition to the deep learning model, we implemented a classical machine learning pipeline using XGBoost to classify pixels individually based on their temporal and spectral profiles.</p>
<p>We use a flattened pixel-wise data. Each input vector represents the spectral evolution of a pixel over time.</p>
<section id="results-1" class="level4">
<h4 class="anchored" data-anchor-id="results-1">Results :</h4>
<table class="table">
<thead>
<tr class="header">
<th><strong>Metric</strong></th>
<th><strong>Score</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Average Loss</td>
<td>0.7358</td>
</tr>
<tr class="even">
<td>Global Accuracy</td>
<td>0.8045</td>
</tr>
<tr class="odd">
<td>Macro Precision</td>
<td>0.3543</td>
</tr>
<tr class="even">
<td>Macro Recall</td>
<td>0.2303</td>
</tr>
<tr class="odd">
<td>Macro F1-score</td>
<td>0.2524</td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="biblio" class="level2">
<h2 class="anchored" data-anchor-id="biblio">biblio</h2>
<p>Mehmet Ozgur Turkoglu, Stefano D’Aronco, Gregor Perich, Frank Liebisch, Constantin Streit, Konrad Schindler, Jan Dirk Wegner, Crop mapping from image time series: Deep learning with multi-scale label hierarchies, Remote Sensing of Environment, Volume 264,2021,112603,ISSN 0034-4257, <a href="https://doi.org/10.1016/j.rse.2021.112603">DOI</a> <a href="https://github.com/0zgur0/multi-stage-convSTAR-network">GitHub</a></p>
</section>
<section id="authors" class="level2">
<h2 class="anchored" data-anchor-id="authors">Authors</h2>
<p>Giovanni Setaro - <a href="https://github.com/giovannisetaro">Github</a></p>
<p>Noé Coursimaux - <a href="https://github.com/NoeCoursi">Github</a></p>
<p>Moïse Placier - <a href="https://github.com/MoisePlacier">Github</a></p>
</section>
</section>
<section id="final-evaluation" class="level1">
<h1>Final Evaluation</h1>
<section id="grade-1.0-97" class="level3">
<h3 class="anchored" data-anchor-id="grade-1.0-97">Grade: 1.0 (97%)</h3>
</section>
<section id="evaluated-on-monday-july-21-2025-1857" class="level3">
<h3 class="anchored" data-anchor-id="evaluated-on-monday-july-21-2025-1857">Evaluated on: Monday, July 21, 2025, 18:57</h3>
</section>
<section id="evaluator-teodor-chiaburu" class="level3">
<h3 class="anchored" data-anchor-id="evaluator-teodor-chiaburu">Evaluator: Teodor Chiaburu</h3>
</section>
<section id="feedback" class="level3">
<h3 class="anchored" data-anchor-id="feedback">Feedback</h3>
<p>“Amazing work! I really appreciate it that you investigated a paper and tried to compare against their results! Really non-trivial problem to solve. Extensive data scraping and preprocessing (great imputation for cloud removal). Very good data exploration and visualization. Extensive training routine on the cluster. Correct splits to preserve the diversity in the areas. Tag is missing (-1P) – you had it as a final commit ‘v 1.0’ ;^) Great repo structure (Confusion Matrices in src/Comparison.ipynb could have looked better ;^) Great work on the slides! Answers to question (spectral bands from Sentinel-2) (-2P)”</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  let localAlternateSentinel = 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>